{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a38269-b4a5-4c64-a1d4-720b1b206a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b35c1d47-288b-4bcb-97c8-9a2f1ca3a293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ultralytics in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.2.39)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (3.8.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.4.0.dev20240604+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.19.0.dev20240604+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: gTTs in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gTTs) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gTTs) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<8.2,>=7.1->gTTs) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->gTTs) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->gTTs) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->gTTs) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->gTTs) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip  install ultralytics\n",
    "! pip  install gTTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78e6f96d-f13e-43aa-ac54-c65c991cbb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: comtypes in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyttsx3) (1.4.4)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\averik\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyttsx3) (306)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb8f783-e18f-44e3-9be2-57d10b44d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da516ffb-d2a0-4cfd-8ce6-efcc69be5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(knownWidth, focalLength, perWidth):\n",
    "    return (knownWidth * focalLength) / perWidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043799b8-b81b-4d23-8928-12784b4ea0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3682f8e-11b6-41e4-9629-068768f6514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Customize the speech rate\n",
    "engine.setProperty('rate', 150)\n",
    "\n",
    "# Customize the volume\n",
    "engine.setProperty('volume', 0.9)\n",
    "\n",
    "# Choose a different voice\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[1].id)  # Choose the second voice\n",
    "\n",
    "# Convert text to speech\n",
    "engine.say(\"Hello!\")\n",
    "engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec872d-e021-4823-8c4c-b4d494532452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82918fe-9859-4eb8-adc4-f07a9a46b76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc39d8e0-ba9f-475d-8268-989241baf840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 158.5ms\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m coords:\n\u001b[0;32m     52\u001b[0m     x,y,w,h \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m---> 53\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(\u001b[43mframe\u001b[49m, (x, y), (x \u001b[38;5;241m+\u001b[39m w, y \u001b[38;5;241m+\u001b[39m h), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     54\u001b[0m     dis \u001b[38;5;241m=\u001b[39m distance(known_widthm, focal_length, w)\n\u001b[0;32m     55\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistance\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inches\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m),\n\u001b[0;32m     56\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.6\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frame' is not defined"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math \n",
    "from gtts import gTTS\n",
    "# start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# model\n",
    "model = YOLO(\"yolov9e.pt\")\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "# object classes\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "known_width = 45\n",
    "focal_length = 450\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model.predict(img, stream=True, conf = 0.7)\n",
    "    #results_str = str(results)\n",
    "    texts = []\n",
    "    distances = []\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    # coordinates\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            # bounding box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "            # put box in cam\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            coords = boxes.xywh\n",
    "            for i in coords:\n",
    "                x,y,w,h = i\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                dis = distance(known_widthm, focal_length, w)\n",
    "                cv2.putText(frame, f\"Distance: {distance:.2f} inches\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                distances.append(dis)\n",
    "                \n",
    "\n",
    "            # confidence\n",
    "           # confidence = math.ceil((box.conf[0]*100))/100\n",
    "            #print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # class name\n",
    "            cls = int(box.cls[0])\n",
    "            #print(\"Class name -->\", classNames[cls])\n",
    "           # result_str = str(classNames[cls])\n",
    "           # engine.say(f' An object{results_str}is at a distance of {distances[]}')\n",
    "            #engine.runAndWait()\n",
    "            texts.append(classNames[cls])\n",
    "\n",
    "            \n",
    "            \n",
    "           # text = classNames[cls]\n",
    "           ## language = 'en'\n",
    "           # myobj = gTTS(text=mytext, lang=language, slow=False)\n",
    "           # myobj.save(\"welcome.mp3\")\n",
    "\n",
    "# Playing the converted file\n",
    "           # os.system(\"Predictions.mp3\")\n",
    "            \n",
    "            \n",
    "\n",
    "            # object details\n",
    "            org = [x1, y1]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 2\n",
    "\n",
    "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    textss = [str(i ) for i in texts]\n",
    "    \n",
    "    for i in range(len(textss)):\n",
    "        engine.say(i)\n",
    "        engine.runAndWait()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8928f7b-f44d-45db-9101-ac8fcb873988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install gTTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "877b9b7d-bbff-450d-8fc3-2f00a909c5df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YOLO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m cap\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m480\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov9e.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m engine \u001b[38;5;241m=\u001b[39m pyttsx3\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'YOLO' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "KNOWN_WIDTH = 45  # Width of the object in inches\n",
    "FOCAL_LENGTH = 450  # This needs to be calibrated for your camera\n",
    "\n",
    "def distance_to_camera(knownWidth, focalLength, perWidth):\n",
    "    return (knownWidth * focalLength) / perWidth\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# model\n",
    "model = YOLO(\"yolov9e.pt\")\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply edge detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the largest contour\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Get bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        \n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Calculate distance\n",
    "        distance = distance_to_camera(KNOWN_WIDTH, FOCAL_LENGTH, w)\n",
    "        \n",
    "        # Display distance on frame\n",
    "        cv2.putText(frame, f\"Distance: {distance:.2f} inches\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d952c67d-cb57-4a21-96f1-ad4355e043cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc44557f-f2f7-4109-92c1-094eb5db554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine =  pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08673a8a-c007-4588-8fcf-4ca708605b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say(f\"hello{1}\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5c5ac7-c674-4d1c-8dd0-83123d7ccbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18bce6-5041-4c6d-bc97-a21bce6c3099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 170.0ms\n",
      "Speed: 1.0ms preprocess, 170.0ms inference, 94.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 49.0ms\n",
      "Speed: 2.0ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 239.7ms\n",
      "Speed: 4.0ms preprocess, 239.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 333.9ms\n",
      "Speed: 3.0ms preprocess, 333.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 337.2ms\n",
      "Speed: 2.0ms preprocess, 337.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 264.9ms\n",
      "Speed: 3.5ms preprocess, 264.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 393.1ms\n",
      "Speed: 3.0ms preprocess, 393.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 301.4ms\n",
      "Speed: 3.0ms preprocess, 301.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 364.1ms\n",
      "Speed: 3.5ms preprocess, 364.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 257.3ms\n",
      "Speed: 3.0ms preprocess, 257.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 48.0ms\n",
      "Speed: 1.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.0ms\n",
      "Speed: 1.0ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 61.0ms\n",
      "Speed: 1.0ms preprocess, 61.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 62.5ms\n",
      "Speed: 1.0ms preprocess, 62.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 66.5ms\n",
      "Speed: 2.0ms preprocess, 66.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 222.3ms\n",
      "Speed: 2.0ms preprocess, 222.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 248.5ms\n",
      "Speed: 3.0ms preprocess, 248.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math \n",
    "from ultralytics import YOLO\n",
    "\n",
    "import pyttsx3\n",
    "import time\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "# Constants\n",
    "known_width = 45  # Width of the object in inches\n",
    "focal_length = 450\n",
    "# model\n",
    "model = YOLO(\"yolov9e.pt\")\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# ... (rest of your imports and setup)\n",
    "\n",
    "def distance(known_width, focal_length, perceived_width):\n",
    "    return (known_width * focal_length) / perceived_width\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model.predict(img, stream=True, conf=0.7)\n",
    "    texts = []\n",
    "    distances = []\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            \n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            \n",
    "            \n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "            \n",
    "            \n",
    "            width = x2 - x1\n",
    "            \n",
    "            \n",
    "            dis = distance(known_width, focal_length, width)\n",
    "            cv2.putText(img, f\"Distance: {dis:.2f} cm\", (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            distances.append(dis)\n",
    "            \n",
    "            \n",
    "            cls = int(box.cls[0])\n",
    "            texts.append(classNames[cls])\n",
    "            \n",
    "            \n",
    "            cv2.putText(img, classNames[cls], (x1, y1 - 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "    for i in range(len(texts)):\n",
    "        engine.say(f\"An object {texts[i]} is at a distance of {distances[i]:.2f} centimeters\")\n",
    "        engine.runAndWait()\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0826e61-e3dd-427f-8b02-d1754f9484e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread(r'C:\\Users\\AVERIK\\OneDrive\\Pictures\\ee6e770a-ba2c-40df-b0c6-f55eed1ddc34.jpeg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Draw rectangles around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "# Save the result\n",
    "cv2.imwrite('detected_faces.jpg', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245a40af-2b2a-4da7-bf3b-d16eb49a127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open a connection to the camera (0 for the default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close the widow\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b56101-42ce-4530-b877-2631230ce22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604536ce-3254-479a-a393-53d0f5aabf02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
